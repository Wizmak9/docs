---
title: 'Deploy Quantised Models'
description: ''
---

Welcome to NextAI, your trusted platform for deploying and managing AI models efficiently. This guide will take you through the process of deploying a quantized AI model on NextAI, allowing you to benefit from models that are optimized for performance and efficiency.

## Step 1: Logging In
1. Visit `https://app.nextai.co.in` and log in with your credentials.
2. Input your **email** and **password**.
3. Hit **Login** to proceed to your dashboard.

## Step 2: Navigating to Deployment Services
1. Find and click on **Model Deployment** or **Services**.
2. Choose **Deploy Model** to enter the deployment area.

## Step 3: Initiating Model Deployment
1. Click on **Add New Model** or **Deploy Model**.
2. Provide the model's details:
   - **Model Name**: Assign a name for identification.
   - **Model Source**: Indicate **Quantized Model**.
   - **Model Framework**: Select the appropriate framework (e.g., TensorFlow Lite).
   - **Repository URL**: If applicable, provide the model's repository URL.
   - **Deployment Configuration**: Define the compute resources like CPU/GPU, memory, etc.

## Step 4: Model Configuration
1. Configure **input/output formats**, **environment variables**, and **dependencies**.
2. Adhere to NextAI's configuration instructions for best results.

## Step 5: Uploading Necessary Artifacts
1. If required, upload the model's **quantized weights** or other artifacts.
2. Ensure completeness of all essential files for the model's functionality.

## Step 6: Finalizing Model Deployment
1. Verify all provided information and configurations.
2. Click **Deploy Model** to commence the deployment process.
3. Monitor the progress through your dashboard notifications.

## Step 7: Model Testing and Integration
1. Post-deployment, test the model with NextAI's interface or through the API.
2. Integrate the model with your application and assess its performance and efficiency.


## Conclusion
Deploying a quantized model on NextAI simplifies the integration of efficient and high-performance AI capabilities into your projects. By following these steps, you can take advantage of quantized models that offer reduced model size and increased inference speed, all within your NextAI account.

If you encounter any issues or have questions, feel free to reach out to our support team for assistance.